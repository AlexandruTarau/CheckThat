Since we were not registered in time for the CLEF2025 platform, we could not submit our predictions through
Codalab. Instead, we used the publicly available file subtask4b_query_tweets_test_gold.tsv, which contains
annotations for the test set, to locally evaluate each model. This allowed us to compute the MRR scores for the test
set using the same metrics defined in the task guidelines.
Additionally, we exported our predictions for the test set in the required TSV format (post id, preds) to match the
expected submission format, as specified in the shared task instructions.
